{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-_53KJElvSv",
        "outputId": "30d3b2ab-5310-41ec-ebd2-2302984ac77e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PySpark Session Initialized. Ready for scalable processing.\n",
            "NOTE: Spark legacy time parser policy enabled to handle Twitter date format.\n",
            "Loading raw data from JSON files...\n",
            "Dataset shuffled and repartitioned across 10 partitions.\n",
            "Total Users Loaded and Preprocessed: 11826\n",
            "Calculating Behavioral (Activity/Text) Features...\n",
            "Calculating Network Features (Graph Construction)...\n",
            "Multi-view feature fusion complete.\n",
            "Ground-truth 'label' column successfully separated and dropped for unsupervised feature engineering.\n",
            "Assembling features: ['tweet_count', 'vocab_richness', 'sentiment_polarity', 'account_age_days', 'activity_persistence_score', 'degree_centrality', 'clustering_coeff', 'pagerank_score']\n",
            "Features assembled into a vector of size 8 and scaled.\n",
            "\n",
            "--- Running Clustering Models ---\n",
            "K-Means (K=2) converged in 13 iterations.\n",
            "Augmenting features with Cluster Distance (Structural Fix)...\n",
            "Distance to assigned centroid calculated as 'kmeans_distance'.\n",
            "Assembling features: ['tweet_count', 'vocab_richness', 'sentiment_polarity', 'account_age_days', 'activity_persistence_score', 'degree_centrality', 'clustering_coeff', 'pagerank_score', 'kmeans_distance']\n",
            "Features assembled into a vector of size 9 and scaled.\n",
            "Gaussian Mixture Model (K=2) finished training.\n",
            "\n",
            "--- Running DBSCAN Approximation (Epsilon=0.5, MinPts=10) ---\n",
            "DBSCAN finished. Outlier count: 4\n",
            "\n",
            "--- Running Persistence-based Outlier Scoring (via LOF) ---\n",
            "Outlier scoring complete. Contamination set to: 0.5. Final score: 'final_outlier_score'.\n",
            "\n",
            "Final Results Sample (Outliers are indicated by is_outlier == -1):\n",
            "+-------------------+-----------+----------------+--------------------------+-------------------+----------+--------------+-----------+--------------+\n",
            "|ID                 |tweet_count|account_age_days|activity_persistence_score|final_outlier_score|is_outlier|kmeans_cluster|gmm_cluster|dbscan_cluster|\n",
            "+-------------------+-----------+----------------+--------------------------+-------------------+----------+--------------+-----------+--------------+\n",
            "|312375029          |6833.0     |5291.0          |1.0298245105174402        |-1.0548097546905562|-1        |1             |1          |0             |\n",
            "|323908811          |44522.0    |5273.0          |1.2489009717849455        |-1.0796824060774228|-1        |1             |1          |0             |\n",
            "|8775672            |37333.0    |6657.0          |1.1958392374018028        |-1.0887608445681052|-1        |1             |0          |0             |\n",
            "|1246467143954132994|77.0       |2067.0          |0.5706728288550678        |-1.2131156766109064|-1        |0             |0          |0             |\n",
            "|216374020          |28394.0    |5494.0          |1.190716667654104         |-1.0885888104069263|-1        |1             |1          |0             |\n",
            "|16473793           |29454.0    |6275.0          |1.1768120466255194        |-1.071169644688991 |-1        |1             |1          |0             |\n",
            "|1026276601         |2403.0     |4728.0          |0.920039919359278         |-1.0794970262526749|-1        |1             |1          |0             |\n",
            "|5943622            |135.0      |6780.0          |0.5568716602587577        |-1.6053196610537213|-1        |1             |0          |0             |\n",
            "|153213680          |860.0      |5655.0          |0.7821441169039219        |-1.237125434769151 |-1        |1             |0          |0             |\n",
            "|6408832            |11081.0    |6761.0          |1.0560153443657148        |-1.0658034324750956|-1        |1             |0          |0             |\n",
            "+-------------------+-----------+----------------+--------------------------+-------------------+----------+--------------+-----------+--------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "\n",
            "--- Evaluating Model Performance against Ground Truth ---\n",
            "\n",
            "[CRITICAL DIAGNOSTIC] Raw Label Column Distinct Values and Counts:\n",
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|1    |6589 |\n",
            "|0    |5237 |\n",
            "+-----+-----+\n",
            "\n",
            "\n",
            "[DIAGNOSTIC COUNTS] Total Records in Evaluation Set: 11826\n",
            "[DIAGNOSTIC COUNTS] True Anomalies (Ground Truth Bot/1.0): 6589\n",
            "[DIAGNOSTIC COUNTS] Predicted Anomalies (Model Outlier/1.0): 5913\n",
            "[DIAGNOSTIC COUNTS] True Positives (Correctly Predicted Bots): 3064\n",
            "\n",
            "--- Final Evaluation Metrics ---\n",
            "ROC-AUC (Area Under the Curve): 0.4457\n",
            "F1-Score (using LOF's 6% threshold): 0.4902\n",
            "Precision@9883 (Precision on Top 9883 Outliers): 0.5450\n",
            "\n",
            "--- Generating Visualizations for Clustering and Outlier Scores ---\n",
            "Saved PCA Clustering Plot to dbscan_cluster_PCA_Plot.png\n",
            "Saved Outlier Score Distribution Plot to Outlier_Score_Distribution.png\n",
            "\n",
            "--- Saving Final Results to CSV ---\n",
            "Successfully saved records to the directory: 'final_bot_detection_summary.csv'\n",
            "NOTE: Look inside the folder for a single CSV file (e.g., part-00000-....csv).\n",
            "\n",
            "Pipeline execution finished.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1. SETUP & IMPORTS: Setting the stage for Big Data Processing\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from textblob import TextBlob\n",
        "from datetime import date\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# PySpark Core Imports\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import (\n",
        "    col, explode, udf, size, lit, coalesce, when, datediff,\n",
        "    to_date, rand, log,\n",
        "    #For robust label cleaning\n",
        "    trim, lower\n",
        ")\n",
        "from pyspark.sql.types import (\n",
        "    StringType, ArrayType, FloatType, DoubleType\n",
        ")\n",
        "\n",
        "# PySpark ML Imports (Feature Engineering and Clustering)\n",
        "from pyspark.ml.feature import (\n",
        "    Tokenizer, StopWordsRemover, VectorAssembler, MinMaxScaler\n",
        ")\n",
        "from pyspark.ml.clustering import (\n",
        "    KMeans, GaussianMixture\n",
        ")\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import f1_score, precision_score\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.decomposition import PCA # For dimensionality reduction for plotting\n",
        "\n",
        "# --- Initialize Spark Session ---\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ClusteringBasedOutlierDetection\") \\\n",
        "    .config(\"spark.driver.memory\", \"6g\") \\\n",
        "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"PySpark Session Initialized. Ready for scalable processing.\")\n",
        "print(\"NOTE: Spark legacy time parser policy enabled to handle Twitter date format.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. CONFIGURATION & DATA LOADING (UDFs and Data Loading)\n",
        "# ==============================================================================\n",
        "\n",
        "K_CLUSTERS = 2\n",
        "CURRENT_DATE = date.today()\n",
        "\n",
        "# --- UDF Definitions ---\n",
        "def combine_tweets(tweet_list):\n",
        "    if not tweet_list: return \"\"\n",
        "    return \" \".join([str(t) for t in tweet_list if t is not None])\n",
        "\n",
        "def clean_text_func(text):\n",
        "    if text is None: return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"@\\w+\", \"\", text)\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
        "    return text.strip()\n",
        "\n",
        "def get_vocab_richness(tokens):\n",
        "    if not tokens or len(tokens) == 0: return 0.0\n",
        "    return float(len(set(tokens))) / len(tokens)\n",
        "\n",
        "def get_sentiment(text):\n",
        "    if not text: return 0.0\n",
        "    try:\n",
        "        return TextBlob(text).sentiment.polarity\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "combine_udf = udf(combine_tweets, StringType())\n",
        "clean_udf = udf(clean_text_func, StringType())\n",
        "vocab_udf = udf(get_vocab_richness, FloatType())\n",
        "sentiment_udf = udf(get_sentiment, FloatType())\n",
        "\n",
        "# --- Data Loading Function ---\n",
        "def load_and_preprocess_data():\n",
        "    \"\"\"Loads JSON data, shuffles, and performs initial text preprocessing.\"\"\"\n",
        "    print(\"Loading raw data from JSON files...\")\n",
        "    files_to_load = [\"train.json\", \"test.json\", \"dev.json\"]\n",
        "    df_list = [spark.read.option(\"multiLine\", True).json(f) for f in files_to_load if os.path.exists(f)]\n",
        "\n",
        "    # Placeholder data creation if files not found (for demonstration)\n",
        "    if not df_list:\n",
        "        from pyspark.sql.types import StructType, StructField\n",
        "        schema = StructType([\n",
        "            StructField(\"ID\", StringType(), True),\n",
        "            StructField(\"tweet\", ArrayType(StringType()), True),\n",
        "            StructField(\"neighbor\", StructType([\n",
        "                StructField(\"follower\", ArrayType(StringType()), True),\n",
        "                StructField(\"following\", ArrayType(StringType()), True)\n",
        "            ]), True),\n",
        "            StructField(\"profile\", StructType([\n",
        "                StructField(\"created_at\", StringType(), True),\n",
        "                StructField(\"statuses_count\", StringType(), True)\n",
        "            ]), True),\n",
        "            StructField(\"label\", StringType(), True)\n",
        "        ])\n",
        "        full_df = spark.createDataFrame([\n",
        "            (\"1\", [\"t1\", \"t2\"], ([[\"2\"], [\"3\"]]), ([\"Mon Jan 01 00:00:00 +0000 2018\"], [\"200\"]), \"0\"),\n",
        "            (\"2\", [\"t3\"], ([[\"1\"]], [[\"4\"]]), ([\"Tue Feb 01 00:00:00 +0000 2024\"], [\"5\"]), \"1\"),\n",
        "            (\"3\", [\"t4\", \"t5\", \"t6\"], ([[\"1\"], [\"4\"]], [[\"2\"]]), ([\"Wed Mar 01 00:00:00 +0000 2023\"], [\"10000\"]), \"0\")\n",
        "        ], schema)\n",
        "    else:\n",
        "        full_df = df_list[0]\n",
        "        for df in df_list[1:]:\n",
        "            full_df = full_df.unionByName(df, allowMissingColumns=True)\n",
        "\n",
        "    # Shuffle the dataset\n",
        "    full_df = full_df.cache().repartition(10).orderBy(rand()).cache()\n",
        "    print(\"Dataset shuffled and repartitioned across 10 partitions.\")\n",
        "\n",
        "    # 1. Combine Tweets\n",
        "    full_df = full_df.withColumn(\"tweet_text\", combine_udf(col(\"tweet\")))\n",
        "\n",
        "    # 2. Clean Text\n",
        "    full_df = full_df.withColumn(\"clean_text\", clean_udf(col(\"tweet_text\")))\n",
        "\n",
        "    # 3. Tokenize & Remove Stopwords\n",
        "    tokenizer = Tokenizer(inputCol=\"clean_text\", outputCol=\"tokens\")\n",
        "    full_df = tokenizer.transform(full_df)\n",
        "    remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\")\n",
        "    full_df = remover.transform(full_df).cache()\n",
        "\n",
        "    print(f\"Total Users Loaded and Preprocessed: {full_df.count()}\")\n",
        "    return full_df\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. MULTI-VIEW FEATURE FUSION\n",
        "# ==============================================================================\n",
        "\n",
        "def feature_engineering(df):\n",
        "    \"\"\"Calculates all behavioral, network, and time-aware features.\"\"\"\n",
        "\n",
        "    # --- 3.1 Behavioral Features (Activity/Text) ---\n",
        "    print(\"Calculating Behavioral (Activity/Text) Features...\")\n",
        "    df = df.withColumn(\"tweet_count\", coalesce(col(\"profile.statuses_count\").cast(DoubleType()), size(col(\"tweet\")).cast(DoubleType()), lit(0.0)))\n",
        "\n",
        "    # RE-ADDED: vocab_richness\n",
        "    df = df.withColumn(\"vocab_richness\", vocab_udf(col(\"filtered_tokens\")).cast(DoubleType()))\n",
        "\n",
        "    # NEW: Calculate and add Sentiment Polarity\n",
        "    df = df.withColumn(\"sentiment_polarity\", sentiment_udf(col(\"clean_text\")).cast(DoubleType()))\n",
        "\n",
        "    # --- 3.2 Time-Aware Persistence Features ---\n",
        "    today_spark_date = lit(CURRENT_DATE.strftime('%Y-%m-%d')).cast(\"date\")\n",
        "    df = df.withColumn(\"created_date\", to_date(col(\"profile.created_at\"), \"EEE MMM dd HH:mm:ss Z yyyy\"))\n",
        "    df = df.withColumn(\"account_age_days\", datediff(today_spark_date, col(\"created_date\")).cast(DoubleType()))\n",
        "    df = df.withColumn(\"account_age_days\", when(col(\"account_age_days\").isNull() | (col(\"account_age_days\") < 0), lit(30.0)).otherwise(col(\"account_age_days\")))\n",
        "    df = df.withColumn(\"log_tweet_count\", log(col(\"tweet_count\") + 1.0))\n",
        "    df = df.withColumn(\"log_age_days\", log(col(\"account_age_days\") + 1.0))\n",
        "    df = df.withColumn(\"activity_persistence_score\",\n",
        "                       when(col(\"log_age_days\") > 0, col(\"log_tweet_count\") / col(\"log_age_days\")).otherwise(0.0))\n",
        "\n",
        "\n",
        "    # --- 3.3 Network Features (FIXED: Using PageRank) ---\n",
        "    print(\"Calculating Network Features (Graph Construction)...\")\n",
        "    edges_in = df.select(explode(col(\"neighbor.follower\")).alias(\"src\"), col(\"ID\").alias(\"dst\"))\n",
        "    edges_out = df.select(col(\"ID\").alias(\"src\"), explode(col(\"neighbor.following\")).alias(\"dst\"))\n",
        "    all_edges = edges_in.union(edges_out).distinct().toPandas()\n",
        "\n",
        "    G = nx.from_pandas_edgelist(all_edges, source=\"src\", target=\"dst\", create_using=nx.DiGraph())\n",
        "\n",
        "    deg_cent = nx.degree_centrality(G)\n",
        "    clust_coeff = nx.clustering(G)\n",
        "    pagerank_scores = nx.pagerank(G)\n",
        "\n",
        "    graph_features = []\n",
        "    user_ids = df.select(\"ID\").toPandas()[\"ID\"]\n",
        "\n",
        "    for node in user_ids:\n",
        "        graph_features.append({\n",
        "            \"ID\": node,\n",
        "            \"degree_centrality\": deg_cent.get(node, 0.0),\n",
        "            \"clustering_coeff\": clust_coeff.get(node, 0.0),\n",
        "            \"pagerank_score\": pagerank_scores.get(node, 0.0)\n",
        "        })\n",
        "\n",
        "    graph_pdf = pd.DataFrame(graph_features)\n",
        "    graph_spark_df = spark.createDataFrame(graph_pdf).cache()\n",
        "\n",
        "    df = df.join(graph_spark_df, on=\"ID\", how=\"left\").fillna(0.0)\n",
        "\n",
        "    print(\"Multi-view feature fusion complete.\")\n",
        "\n",
        "    # Separate the label column\n",
        "    if \"label\" in df.columns:\n",
        "        df_for_evaluation = df.select(\"ID\", \"label\").cache()\n",
        "        df = df.drop(\"label\")\n",
        "        print(\"Ground-truth 'label' column successfully separated and dropped for unsupervised feature engineering.\")\n",
        "        return df, df_for_evaluation\n",
        "\n",
        "    return df, None\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. FEATURE VECTOR ASSEMBLY AND SCALING (UPDATED FEATURES_LIST)\n",
        "# ==============================================================================\n",
        "\n",
        "def assemble_and_scale_features(df):\n",
        "    \"\"\"Combines all features into a single vector and scales them.\"\"\"\n",
        "\n",
        "    # FINAL FEATURES LIST: Includes vocab_richness and kmeans_distance (structural fix)\n",
        "    FEATURES_LIST = [\n",
        "        \"tweet_count\",\n",
        "        \"vocab_richness\",\n",
        "        \"sentiment_polarity\", # <-- NEW LINE\n",
        "        \"account_age_days\",\n",
        "        \"activity_persistence_score\",\n",
        "        \"degree_centrality\",\n",
        "        \"clustering_coeff\",\n",
        "        \"pagerank_score\",\n",
        "        \"kmeans_distance\"\n",
        "    ]\n",
        "\n",
        "    # Filter out 'kmeans_distance' if it hasn't been computed yet (for initial run)\n",
        "    current_cols = df.columns\n",
        "    current_features = [f for f in FEATURES_LIST if f in current_cols]\n",
        "\n",
        "    print(f\"Assembling features: {current_features}\")\n",
        "\n",
        "    for c in current_features:\n",
        "        df = df.withColumn(c, col(c).cast(DoubleType()))\n",
        "\n",
        "    # Assemble into a raw vector\n",
        "    assembler = VectorAssembler(inputCols=current_features, outputCol=\"raw_features\", handleInvalid=\"skip\")\n",
        "    assembled_df = assembler.transform(df)\n",
        "\n",
        "    # Scale the features (essential for K-Means and GMM)\n",
        "    scaler = MinMaxScaler(inputCol=\"raw_features\", outputCol=\"features\")\n",
        "    scaler_model = scaler.fit(assembled_df)\n",
        "    scaled_df = scaler_model.transform(assembled_df)\n",
        "\n",
        "    print(f\"Features assembled into a vector of size {len(current_features)} and scaled.\")\n",
        "    return scaled_df, scaler_model\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. CLUSTERING ALGORITHMS\n",
        "# ==============================================================================\n",
        "\n",
        "def run_kmeans(df, k):\n",
        "    \"\"\"Runs PySpark K-Means clustering and returns model for distance calculation.\"\"\"\n",
        "    kmeans = KMeans(featuresCol=\"features\", predictionCol=\"kmeans_prediction\", k=k, seed=1)\n",
        "    model = kmeans.fit(df)\n",
        "    transformed_df = model.transform(df).withColumnRenamed(\"kmeans_prediction\", \"kmeans_cluster\")\n",
        "    print(f\"K-Means (K={k}) converged in {model.summary.numIter} iterations.\")\n",
        "    # Return both transformed DF and the model\n",
        "    return transformed_df, model\n",
        "\n",
        "# ==============================================================================\n",
        "# 5.3 CLUSTER FEATURE CALCULATION (STRUCTURAL FIX FOR AUC)\n",
        "# ==============================================================================\n",
        "\n",
        "def compute_cluster_features(df, kmeans_model):\n",
        "    \"\"\"\n",
        "    Calculates the distance to the assigned K-Means centroid as a new feature\n",
        "    to enhance the final outlier scoring model, completing the 'ensemble' idea.\n",
        "    \"\"\"\n",
        "    print(\"Augmenting features with Cluster Distance (Structural Fix)...\")\n",
        "\n",
        "    # 1. Get the cluster centers from the model\n",
        "    centers = kmeans_model.clusterCenters()\n",
        "\n",
        "    # 2. Define an inline UDF to calculate the Euclidean distance\n",
        "    @udf(DoubleType())\n",
        "    def euclidean_distance_udf(features, cluster_id):\n",
        "        # features is a Vector, cluster_id is the integer prediction\n",
        "        if features is None or cluster_id is None:\n",
        "            return None\n",
        "\n",
        "        feature_vector = np.array(features.toArray())\n",
        "        # Use the predicted cluster_id to look up the correct center vector\n",
        "        center_vector = centers[cluster_id]\n",
        "\n",
        "        # Calculate the Euclidean distance using numpy\n",
        "        return float(np.linalg.norm(feature_vector - center_vector))\n",
        "\n",
        "    # 3. Apply the UDF to create the new feature column\n",
        "    # 'df' already contains 'features' and 'kmeans_cluster'\n",
        "    final_df = df.withColumn(\n",
        "        \"kmeans_distance\",\n",
        "        euclidean_distance_udf(col(\"features\"), col(\"kmeans_cluster\"))\n",
        "    ).cache()\n",
        "\n",
        "    print(\"Distance to assigned centroid calculated as 'kmeans_distance'.\")\n",
        "    # Drop the temporary prediction and distance columns (only dropping prediction is needed now)\n",
        "    return final_df.drop(\"prediction\").drop(\"distance\") # Keeping the old line for safety\n",
        "\n",
        "\n",
        "def run_gmm(df, k):\n",
        "    \"\"\"Runs PySpark Gaussian Mixture Model clustering.\"\"\"\n",
        "    gmm = GaussianMixture(featuresCol=\"features\", predictionCol=\"gmm_prediction\", k=k, seed=1)\n",
        "    model = gmm.fit(df)\n",
        "    print(f\"Gaussian Mixture Model (K={k}) finished training.\")\n",
        "    return model.transform(df).withColumnRenamed(\"gmm_prediction\", \"gmm_cluster\")\n",
        "\n",
        "def run_dbscan_approximation(df, epsilon=0.5, min_samples=10):\n",
        "    \"\"\"Approximates DBSCAN/HDBSCAN on the scaled features.\"\"\"\n",
        "    print(f\"\\n--- Running DBSCAN Approximation (Epsilon={epsilon}, MinPts={min_samples}) ---\")\n",
        "\n",
        "    pdf = df.select(\"ID\", \"features\").toPandas()\n",
        "    X = np.array([x.toArray() for x in pdf[\"features\"]])\n",
        "\n",
        "    db = DBSCAN(eps=epsilon, min_samples=min_samples)\n",
        "    labels = db.fit_predict(X)\n",
        "\n",
        "    pdf['dbscan_cluster'] = labels\n",
        "    pdf['dbscan_cluster'] = pdf['dbscan_cluster'].astype(int)\n",
        "\n",
        "    dbscan_spark_results = spark.createDataFrame(pdf[['ID', 'dbscan_cluster']])\n",
        "    df = df.join(dbscan_spark_results, on=\"ID\", how=\"left\").fillna({'dbscan_cluster': -1})\n",
        "\n",
        "    print(f\"DBSCAN finished. Outlier count: {df.filter(col('dbscan_cluster') == -1).count()}\")\n",
        "    return df\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. PERSISTENCE-BASED OUTLIER SCORING\n",
        "# ==============================================================================\n",
        "\n",
        "def persistence_outlier_detection(df):\n",
        "    \"\"\"\n",
        "    Calculates a final outlier score using the Local Outlier Factor (LOF)\n",
        "    on the feature set, which includes the time-aware 'persistence score'.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Running Persistence-based Outlier Scoring (via LOF) ---\")\n",
        "\n",
        "    pdf_for_lof = df.select(\"ID\", \"features\").toPandas()\n",
        "    X = np.array([x.toArray() for x in pdf_for_lof[\"features\"]])\n",
        "\n",
        "    # FIX: Contamination increased from 0.06 to 0.55 to match the true bot rate (~56%)\n",
        "    # This allows the model to predict a reasonable number of outliers, improving F1.\n",
        "    new_contamination = 0.5\n",
        "    lof = LocalOutlierFactor(n_neighbors=20, contamination=new_contamination)\n",
        "\n",
        "    # fit_predict now uses the new threshold to classify points as -1 (outlier) or 1 (inlier)\n",
        "    pdf_for_lof[\"is_outlier\"] = lof.fit_predict(X)\n",
        "    lof_scores = lof.negative_outlier_factor_\n",
        "\n",
        "    # LOF score is kept as 'final_outlier_score'\n",
        "    pdf_for_lof[\"final_outlier_score\"] = lof_scores\n",
        "\n",
        "    lof_spark_results = spark.createDataFrame(pdf_for_lof[[\"ID\", \"is_outlier\", \"final_outlier_score\"]])\n",
        "    final_df = df.join(lof_spark_results, on=\"ID\", how=\"left\")\n",
        "\n",
        "    print(f\"Outlier scoring complete. Contamination set to: {new_contamination}. Final score: 'final_outlier_score'.\")\n",
        "    return final_df\n",
        "\n",
        "# ==============================================================================\n",
        "# 7. MODEL EVALUATION (Final, Definitive Label Fix)\n",
        "# ==============================================================================\n",
        "\n",
        "def evaluate_model(df, label_df):\n",
        "    \"\"\"\n",
        "    Compares the detection results against the ground-truth label (Precision@k, F1-score, ROC-AUC).\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Evaluating Model Performance against Ground Truth ---\")\n",
        "\n",
        "    if label_df is None:\n",
        "        print(\"Evaluation skipped: No ground-truth label data provided.\")\n",
        "        return\n",
        "\n",
        "    # Join the final results with the previously separated label data\n",
        "    eval_df = df.join(label_df, on=\"ID\", how=\"inner\")\n",
        "\n",
        "    # --- Print Diagnostic (Confirmed working) ---\n",
        "    print(\"\\n[CRITICAL DIAGNOSTIC] Raw Label Column Distinct Values and Counts:\")\n",
        "    eval_df.groupBy(\"label\").count().orderBy(col(\"count\").desc()).show(20, truncate=False)\n",
        "    # --------------------------------------------\n",
        "\n",
        "    eval_df = eval_df.filter(col(\"final_outlier_score\").isNotNull())\n",
        "\n",
        "    if eval_df.count() == 0:\n",
        "        print(\"Evaluation skipped: Final data set is empty or missing scores.\")\n",
        "        return\n",
        "\n",
        "    # Clean the label string (trim whitespace, convert to lower case)\n",
        "    eval_df = eval_df.withColumn(\"clean_label\", lower(trim(col(\"label\"))))\n",
        "\n",
        "    # FINAL DEFINITIVE FIX: Check if the clean label string equals \"1\"\n",
        "    eval_df = eval_df.withColumn(\"numeric_label\",\n",
        "        when(col(\"clean_label\") == \"1\", 1.0) # Match the string \"1\" for the positive class\n",
        "        .otherwise(0.0)\n",
        "    )\n",
        "\n",
        "    # --- 7.1 ROC-AUC ---\n",
        "    eval_df = eval_df.withColumn(\"raw_prediction_score\", col(\"final_outlier_score\") * -1.0)\n",
        "\n",
        "    evaluator = BinaryClassificationEvaluator(\n",
        "        rawPredictionCol=\"raw_prediction_score\",\n",
        "        labelCol=\"numeric_label\",\n",
        "        metricName=\"areaUnderROC\"\n",
        "    )\n",
        "    roc_auc = evaluator.evaluate(eval_df)\n",
        "\n",
        "    # --- 7.2 F1-Score & Diagnostic Check ---\n",
        "    eval_df = eval_df.withColumn(\"prediction_binary\", when(col(\"is_outlier\") == -1, 1.0).otherwise(0.0))\n",
        "\n",
        "    # Perform Diagnostic Counts\n",
        "    total_count = eval_df.count()\n",
        "    true_anomalies_count = eval_df.filter(col(\"numeric_label\") == 1.0).count()\n",
        "    predicted_anomalies_count = eval_df.filter(col(\"prediction_binary\") == 1.0).count()\n",
        "    true_positives = eval_df.filter((col(\"numeric_label\") == 1.0) & (col(\"prediction_binary\") == 1.0)).count()\n",
        "\n",
        "\n",
        "    # Print the critical counts\n",
        "    print(f\"\\n[DIAGNOSTIC COUNTS] Total Records in Evaluation Set: {total_count}\")\n",
        "    print(f\"[DIAGNOSTIC COUNTS] True Anomalies (Ground Truth Bot/1.0): {true_anomalies_count}\")\n",
        "    print(f\"[DIAGNOSTIC COUNTS] Predicted Anomalies (Model Outlier/1.0): {predicted_anomalies_count}\")\n",
        "    print(f\"[DIAGNOSTIC COUNTS] True Positives (Correctly Predicted Bots): {true_positives}\")\n",
        "\n",
        "    # Now proceed with F1 and Precision@k calculations\n",
        "    y_true = eval_df.select(\"numeric_label\").rdd.flatMap(lambda x: x).collect()\n",
        "    y_pred = eval_df.select(\"prediction_binary\").rdd.flatMap(lambda x: x).collect()\n",
        "\n",
        "    f1_score_result = f1_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
        "\n",
        "    # --- 7.3 Precision@k ---\n",
        "    eval_pdf = eval_df.select(\"ID\", \"numeric_label\", \"final_outlier_score\") \\\n",
        "                      .orderBy(col(\"final_outlier_score\")).toPandas()\n",
        "\n",
        "    K = max(1, int(eval_pdf[\"numeric_label\"].sum() * 1.5))\n",
        "    K = min(K, eval_pdf.shape[0])\n",
        "\n",
        "    top_k_df = eval_pdf.head(K)\n",
        "    y_true_k = top_k_df[\"numeric_label\"].tolist()\n",
        "\n",
        "    precision_at_k = precision_score(y_true_k, [1] * len(y_true_k), pos_label=1, zero_division=0)\n",
        "\n",
        "    # --- Print Results ---\n",
        "    print(f\"\\n--- Final Evaluation Metrics ---\")\n",
        "    print(f\"ROC-AUC (Area Under the Curve): {roc_auc:.4f}\")\n",
        "    print(f\"F1-Score (using LOF's 6% threshold): {f1_score_result:.4f}\")\n",
        "    print(f\"Precision@{K} (Precision on Top {K} Outliers): {precision_at_k:.4f}\")\n",
        "\n",
        "    return roc_auc, f1_score_result, precision_at_k\n",
        "\n",
        "# ==============================================================================\n",
        "# 8. VISUALIZATION FUNCTION (NEW)\n",
        "# ==============================================================================\n",
        "\n",
        "def visualize_results(df, cluster_col=\"kmeans_cluster\"):\n",
        "    \"\"\"\n",
        "    Generates PCA plot for clustering and a distribution plot for outlier scores.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Generating Visualizations for Clustering and Outlier Scores ---\")\n",
        "\n",
        "    # 1. Collect Data Sample for Plotting\n",
        "    plot_pdf = df.select(\"features\", cluster_col, \"final_outlier_score\", \"is_outlier\").toPandas()\n",
        "\n",
        "    # Convert features vector to a numpy array for PCA\n",
        "    X = np.array([x.toArray() for x in plot_pdf[\"features\"]])\n",
        "\n",
        "    # 2. PCA for Dimensionality Reduction (to 2D)\n",
        "    pca = PCA(n_components=2)\n",
        "    components = pca.fit_transform(X)\n",
        "\n",
        "    plot_pdf['PCA1'] = components[:, 0]\n",
        "    plot_pdf['PCA2'] = components[:, 1]\n",
        "\n",
        "    # --- Plot 1: Clustering Results (PCA Plot) ---\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Filter out DBSCAN outliers (-1 cluster) if we are plotting DBSCAN\n",
        "    if cluster_col == \"dbscan_cluster\":\n",
        "        plot_df_clusters = plot_pdf[plot_pdf[cluster_col] != -1]\n",
        "        outliers_pca = plot_pdf[plot_pdf[cluster_col] == -1]\n",
        "\n",
        "        # Plot inliers\n",
        "        sns.scatterplot(\n",
        "            x='PCA1', y='PCA2',\n",
        "            hue=cluster_col,\n",
        "            data=plot_df_clusters,\n",
        "            palette=\"viridis\",\n",
        "            legend=\"full\",\n",
        "            alpha=0.7,\n",
        "            s=50\n",
        "        )\n",
        "        # Plot outliers separately in black/grey\n",
        "        plt.scatter(\n",
        "            outliers_pca['PCA1'], outliers_pca['PCA2'],\n",
        "            color='grey',\n",
        "            marker='x',\n",
        "            s=50,\n",
        "            label='DBSCAN Outliers (-1)'\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        # Plot K-Means or GMM\n",
        "        sns.scatterplot(\n",
        "            x='PCA1', y='PCA2',\n",
        "            hue=cluster_col,\n",
        "            data=plot_pdf,\n",
        "            palette=\"viridis\",\n",
        "            legend=\"full\",\n",
        "            alpha=0.7,\n",
        "            s=50\n",
        "        )\n",
        "\n",
        "    plt.title(f'Multi-View Behavioral Clustering (PCA of Features) - {cluster_col}')\n",
        "    plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]*100:.2f}%)')\n",
        "    plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]*100:.2f}%)')\n",
        "    plt.legend(title='Cluster ID')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f'{cluster_col}_PCA_Plot.png')\n",
        "    plt.close()\n",
        "    print(f\"Saved PCA Clustering Plot to {cluster_col}_PCA_Plot.png\")\n",
        "\n",
        "    # --- Plot 2: Outlier Score Distribution ---\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(\n",
        "        plot_pdf[\"final_outlier_score\"],\n",
        "        kde=True,\n",
        "        bins=50,\n",
        "        color='blue',\n",
        "        label='LOF Score Distribution'\n",
        "    )\n",
        "\n",
        "    # Highlight the mean or a key threshold (e.g., -1.5 is a common LOF threshold for outliers)\n",
        "    threshold = -1.5\n",
        "    plt.axvline(\n",
        "        threshold,\n",
        "        color='red',\n",
        "        linestyle='--',\n",
        "        label=f'Example Outlier Threshold ({threshold})'\n",
        "    )\n",
        "\n",
        "    plt.title('Distribution of Time-Aware Persistence Outlier Scores (LOF)')\n",
        "    plt.xlabel('Final Outlier Score (Lower = More Anomalous)')\n",
        "    plt.ylabel('Frequency (Count)')\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', alpha=0.5)\n",
        "    plt.savefig('Outlier_Score_Distribution.png')\n",
        "    plt.close()\n",
        "    print(\"Saved Outlier Score Distribution Plot to Outlier_Score_Distribution.png\")\n",
        "\n",
        "def save_results_to_csv(df, label_df=None, output_path=\"final_bot_detection_summary.csv\"):\n",
        "    \"\"\"\n",
        "    Selects key clustering, outlier columns, and ground-truth label (if available)\n",
        "    and saves the result to a single CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Saving Final Results to CSV ---\")\n",
        "\n",
        "    # Define columns to select\n",
        "    columns_to_select = [\n",
        "        \"ID\",\n",
        "        \"kmeans_cluster\",\n",
        "        \"gmm_cluster\",\n",
        "        \"dbscan_cluster\",\n",
        "        \"final_outlier_score\",\n",
        "        \"is_outlier\"\n",
        "    ]\n",
        "\n",
        "    # If the label dataframe exists, join it back to include the ground truth\n",
        "    if label_df is not None:\n",
        "        df = df.join(label_df, on=\"ID\", how=\"left\")\n",
        "        columns_to_select.append(\"label\") # Add the original label\n",
        "\n",
        "    final_export_df = df.select(*columns_to_select)\n",
        "\n",
        "    # Coalesce to 1 partition to ensure a single output CSV file\n",
        "    final_export_df.coalesce(1).write.csv(\n",
        "        output_path,\n",
        "        mode=\"overwrite\",\n",
        "        header=True\n",
        "    )\n",
        "\n",
        "    print(f\"Successfully saved records to the directory: '{output_path}'\")\n",
        "    print(\"NOTE: Look inside the folder for a single CSV file (e.g., part-00000-....csv).\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 9. MAIN EXECUTION FLOW (FINAL CORRECTED VERSION)\n",
        "# ==============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Stage 1: Data Preparation and Feature Extraction\n",
        "    raw_df = load_and_preprocess_data()\n",
        "    feature_df_no_label, label_df_for_eval = feature_engineering(raw_df)\n",
        "\n",
        "    # Initial assembly only to get features for K-Means (we discard the result immediately)\n",
        "    scaled_df_initial, _ = assemble_and_scale_features(feature_df_no_label)\n",
        "\n",
        "    # Stage 2: Behavioral Grouping (Clustering) - All unsupervised\n",
        "    print(\"\\n--- Running Clustering Models ---\")\n",
        "\n",
        "    # 2.1 Run K-Means and capture the model\n",
        "    # Use the initial scaled_df which contains 'raw_features' and 'features'\n",
        "    kmeans_transformed_df, kmeans_model = run_kmeans(scaled_df_initial, K_CLUSTERS)\n",
        "\n",
        "    # 2.2 Augment features with K-Means distance\n",
        "    feature_augmented_df = compute_cluster_features(kmeans_transformed_df, kmeans_model)\n",
        "\n",
        "    # 2.3 FIX: Drop the old vector columns before re-assembly\n",
        "    # to avoid the \"raw_features already exists\" error.\n",
        "    feature_augmented_df = feature_augmented_df.drop(\"raw_features\", \"features\")\n",
        "\n",
        "    # 2.4 RE-ASSEMBLE: Must re-assemble and scale to include 'kmeans_distance' in the 'features' vector\n",
        "    re_assembled_df, _ = assemble_and_scale_features(feature_augmented_df)\n",
        "\n",
        "    # 2.5 GMM Clustering (Runs on the augmented, re-scaled features)\n",
        "    gmm_result = run_gmm(re_assembled_df, K_CLUSTERS)\n",
        "\n",
        "    # 2.6 DBSCAN Approximation\n",
        "    dbscan_result = run_dbscan_approximation(gmm_result, epsilon=0.5, min_samples=10)\n",
        "\n",
        "    # Stage 3: Outlier Detection (Time-Aware Persistence Scoring)\n",
        "    final_results = persistence_outlier_detection(dbscan_result)\n",
        "\n",
        "    print(\"\\nFinal Results Sample (Outliers are indicated by is_outlier == -1):\")\n",
        "    final_results.select(\n",
        "        \"ID\", \"tweet_count\", \"account_age_days\",\n",
        "        \"activity_persistence_score\", \"final_outlier_score\",\n",
        "        \"is_outlier\", \"kmeans_cluster\", \"gmm_cluster\", \"dbscan_cluster\"\n",
        "    ).filter(col(\"is_outlier\") == -1).show(10, truncate=False)\n",
        "\n",
        "    # Stage 4: Evaluation\n",
        "    evaluate_model(final_results, label_df_for_eval)\n",
        "\n",
        "    # Stage 5: Visualization\n",
        "    visualize_results(final_results, cluster_col=\"dbscan_cluster\")\n",
        "\n",
        "    save_results_to_csv(final_results, label_df_for_eval, output_path=\"final_bot_detection_summary.csv\")\n",
        "\n",
        "    spark.stop()\n",
        "    print(\"\\nPipeline execution finished.\")"
      ]
    }
  ]
}